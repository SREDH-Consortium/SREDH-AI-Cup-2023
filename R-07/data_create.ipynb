{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train format\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "  \n",
    "df = pd.read_csv(\"/home/ting/code/AI_CUP_2023_Medical/First_Phase_Release(Correction)/answer.txt\",keep_default_na=False, na_values=['NaN', 'null'], sep=\"\\t\",names=[\"file_id\", \"label\",\"start_pos\",\"end_pos\",\"entity\",\"time_regular\"])\n",
    "all_file_name = os.listdir(\"/home/ting/code/AI_CUP_2023_Medical/First_Phase_Release(Correction)/First_Phase_Text_Dataset\")\n",
    "  \n",
    "all_data = {}\n",
    "all_label = []\n",
    "with open(\"raw_data/all_train_data.jsonl\", \"w\") as outfile:\n",
    "    for train_file_id in all_file_name:\n",
    "        file_id = train_file_id.split(\".\")[0]\n",
    "        sector = df.groupby([\"file_id\"])\n",
    "        entity_span = sector.get_group(file_id)[['file_id','start_pos', 'end_pos','label','entity']]\n",
    "        annotations = []\n",
    "        save_answer = []\n",
    "        for i,line in entity_span.iterrows():\n",
    "            tmp_answer={}\n",
    "            tmp_answer[\"start\"] = int(line[\"start_pos\"])\n",
    "            tmp_answer[\"end\"] = int(line[\"end_pos\"])\n",
    "            tmp_answer[\"label\"] = line[\"label\"]\n",
    "            all_label.append(line[\"label\"])\n",
    "            save_answer.append(tmp_answer)\n",
    "            # break\n",
    "        with open(\"/home/ting/code/AI_CUP_2023_Medical/First_Phase_Release(Correction)/First_Phase_Text_Dataset/\"+file_id+\".txt\") as f_t:\n",
    "            document = f_t.read()\n",
    "        # print(save_answer)\n",
    "        all_data[\"text\"] = document\n",
    "        all_data[\"meta\"] = {\"note_id\":file_id}\n",
    "        all_data[\"spans\"] = save_answer\n",
    "        json.dump(all_data, outfile)\n",
    "        outfile.write('\\n')\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dev format\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "  \n",
    "df = pd.read_csv(\"/home/ting/code/AI_CUP_2023_Medical/First_Phase_Release(Correction)/val_answer.txt\",keep_default_na=False, na_values=['NaN', 'null'], sep=\"\\t\",names=[\"file_id\", \"label\",\"start_pos\",\"end_pos\",\"entity\",\"time_regular\"])\n",
    "all_file_name = os.listdir(\"/home/ting/code/AI_CUP_2023_Medical/First_Phase_Release(Correction)/Validation_Release\")\n",
    "  \n",
    "all_data = {}\n",
    "all_label = []\n",
    "with open(\"raw_data/all_valid_data.jsonl\", \"w\") as outfile:\n",
    "    for train_file_id in all_file_name:\n",
    "        file_id = train_file_id.split(\".\")[0]\n",
    "        sector = df.groupby([\"file_id\"])\n",
    "        entity_span = sector.get_group(file_id)[['file_id','start_pos', 'end_pos','label','entity']]\n",
    "        annotations = []\n",
    "        save_answer = []\n",
    "        for i,line in entity_span.iterrows():\n",
    "            tmp_answer={}\n",
    "            tmp_answer[\"start\"] = int(line[\"start_pos\"])\n",
    "            tmp_answer[\"end\"] = int(line[\"end_pos\"])\n",
    "            tmp_answer[\"label\"] = line[\"label\"]\n",
    "            all_label.append(line[\"label\"])\n",
    "            save_answer.append(tmp_answer)\n",
    "            # break\n",
    "        with open(\"/home/ting/code/AI_CUP_2023_Medical/First_Phase_Release(Correction)/Validation_Release/\"+file_id+\".txt\") as f_t:\n",
    "            document = f_t.read()\n",
    "        # print(save_answer)\n",
    "        all_data[\"text\"] = document\n",
    "        all_data[\"meta\"] = {\"note_id\":file_id}\n",
    "        all_data[\"spans\"] = save_answer\n",
    "        json.dump(all_data, outfile)\n",
    "        outfile.write('\\n')\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test format\n",
    "import json\n",
    "import os\n",
    "all_data = {}\n",
    "all_file_name = os.listdir(\"TEST_DATASET/opendid_test\")\n",
    "\n",
    "with open(\"raw_data/formal_test_data.jsonl\", \"w\") as outfile:\n",
    "    for name in all_file_name:\n",
    "        with open(\"TEST_DATASET/opendid_test/\"+name) as f_w:\n",
    "            text = f_w.read()\n",
    "            all_data[\"text\"] = text\n",
    "            all_data[\"meta\"] = {\"note_id\":name.split(\".\")[0]}\n",
    "            all_data[\"spans\"] = []\n",
    "            json.dump(all_data, outfile)\n",
    "            outfile.write('\\n')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deidentify",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
