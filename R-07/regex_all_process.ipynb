{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function 定義\n",
    "import re\n",
    "def text2int(textnum, numwords={}):\n",
    "    if not numwords:\n",
    "      units = [\n",
    "        \"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\n",
    "        \"nine\", \"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\",\n",
    "        \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\",\n",
    "      ]\n",
    "\n",
    "      tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n",
    "\n",
    "      scales = [\"hundred\", \"thousand\", \"million\", \"billion\", \"trillion\"]\n",
    "\n",
    "      numwords[\"and\"] = (1, 0)\n",
    "      for idx, word in enumerate(units):    numwords[word] = (1, idx)\n",
    "      for idx, word in enumerate(tens):     numwords[word] = (1, idx * 10)\n",
    "      for idx, word in enumerate(scales):   numwords[word] = (10 ** (idx * 3 or 2), 0)\n",
    "\n",
    "    current = result = 0\n",
    "    for word in textnum.split():\n",
    "        if word not in numwords:\n",
    "          raise Exception(\"Illegal word: \" + word)\n",
    "\n",
    "        scale, increment = numwords[word]\n",
    "        current = current * scale + increment\n",
    "        if scale > 100:\n",
    "            result += current\n",
    "            current = 0\n",
    "\n",
    "    return result + current\n",
    "print(text2int(\"one hundred\"))\n",
    "def reg_set_new(answer):\n",
    "    mapping_dict = {\"R1\":[\"once\", \"one time\"], \"R2\":[\"twice\", \"two times\"], \"R3\": [\"thrice\", \"three times\"], \n",
    "                    \"R4\": [\"four times\"], \"R5\": [\"five times\"], \"R6\": [\"six times\"]}\n",
    "    reg_answer = None\n",
    "    for index, item in enumerate(mapping_dict.items()):\n",
    "        if answer in item[1]:\n",
    "            reg_answer = item[0]\n",
    "    if reg_answer == None:\n",
    "        answer_number = re.findall(r'([\\d]+)[ ]*([t]*[i]*[m]*[e]*[s]*)',answer)\n",
    "        # print(answer_number)\n",
    "        if answer_number == []:\n",
    "            answer_number = answer.split()\n",
    "        elif len(answer_number) >= 1:\n",
    "            answer_number = list(answer_number[0])\n",
    "            answer_number = answer_number[:-1]\n",
    "        answer_number = \" \".join(answer_number).replace(\"-\",\" \").replace(\".\",\" \")\n",
    "        # print(answer_number)\n",
    "        if not answer_number.isdigit():\n",
    "            try:\n",
    "                answer_number = str(text2int(answer_number))\n",
    "            except:\n",
    "                answer_number = answer_number.split()[:-1]\n",
    "                answer_number = str(text2int(\" \".join(answer_number)))\n",
    "        reg_answer = f'R{answer_number}'\n",
    "\n",
    "\n",
    "    return reg_answer\n",
    "\n",
    "import pycountry\n",
    "\n",
    "def is_country_name(name):\n",
    "    # 創建一個包含所有國家的集合\n",
    "    countries = {country.name.lower().replace(\" \",\"\") for country in pycountry.countries}\n",
    "    # 檢查提供的名稱是否在國家名單中\n",
    "    return name.lower().replace(\" \",\"\") in countries\n",
    "def Month_format(origin_month):\n",
    "    month = re.sub(r'[Nn][Oo][Vv][Ee]?[Mm]?[Bb]?[Ee]?[Rr]?', 'November', origin_month)\n",
    "    month = re.sub(r'[Jj][Aa][Nn][Uu]?[Aa]?[Rr]?[Yy]?', 'January', month)\n",
    "    month = re.sub(r'[Ff][Ee][Bb][Rr]?[Uu]?[Aa]?[Rr]?[Yy]?', 'February', month)\n",
    "    month = re.sub(r'[Mm][Aa][Rr][Cc]?[Hh]?', 'March', month)\n",
    "    month = re.sub(r'[Aa][Pp][Rr][Ii]?[Ll]?', 'April', month)\n",
    "    month = re.sub(r'[Mm][Aa][Yy]', 'May', month)\n",
    "    month = re.sub(r'[Jj][Uu][Nn][Ee]?', 'June', month)\n",
    "    month = re.sub(r'[Jj][Uu][Ll][Yy]?', 'July', month)\n",
    "    month = re.sub(r'[Aa][Uu][Gg][Uu]?[Ss]?[Tt]?', 'August', month)\n",
    "    month = re.sub(r'[Ss][Ee][Pp][Tt]?[Ee]?[Mm]?[Bb]?[Ee]?[Rr]?', 'September', month)\n",
    "    month = re.sub(r'[Oo][Cc][Tt][Oo]?[Bb]?[Ee]?[Rr]?', 'October', month)\n",
    "    month = re.sub(r'[Nn][Oo][Vv][Ee]?[Mm]?[Bb]?[Ee]?[Rr]?', 'November', month)\n",
    "    month = re.sub(r'[Dd][Ee][Cc][Ee]?[Mm]?[Bb]?[Ee]?[Rr]?', 'December', month)\n",
    "    return month\n",
    "def Find_Month(text):\n",
    "    find_it=[]\n",
    "    find_it.extend(re.findall(r'[Nn][Oo][Vv][Ee]?[Mm]?[Bb]?[Ee]?[Rr]?', text))\n",
    "    find_it.extend(re.findall(r'[Jj][Aa][Nn][Uu]?[Aa]?[Rr]?[Yy]?', text))\n",
    "    find_it.extend(re.findall(r'[Ff][Ee][Bb][Rr]?[Uu]?[Aa]?[Rr]?[Yy]?', text))\n",
    "    find_it.extend(re.findall(r'[Mm][Aa][Rr][Cc]?[Hh]?',  text))\n",
    "    find_it.extend(re.findall(r'[Aa][Pp][Rr][Ii]?[Ll]?', text))\n",
    "    find_it.extend(re.findall(r'[Mm][Aa][Yy]',  text))\n",
    "    find_it.extend(re.findall(r'[Jj][Uu][Nn][Ee]?', text))\n",
    "    find_it.extend(re.findall(r'[Jj][Uu][Ll][Yy]?', text))\n",
    "    find_it.extend(re.findall(r'[Aa][Uu][Gg][Uu]?[Ss]?[Tt]?',  text))\n",
    "    find_it.extend(re.findall(r'[Ss][Ee][Pp][Tt]?[Ee]?[Mm]?[Bb]?[Ee]?[Rr]?',  text))\n",
    "    find_it.extend(re.findall(r'[Oo][Cc][Tt][Oo]?[Bb]?[Ee]?[Rr]?',  text))\n",
    "    find_it.extend(re.findall(r'[Nn][Oo][Vv][Ee]?[Mm]?[Bb]?[Ee]?[Rr]?',  text))\n",
    "    find_it.extend(re.findall(r'[Dd][Ee][Cc][Ee]?[Mm]?[Bb]?[Ee]?[Rr]?',  text))\n",
    "    return find_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Post Process\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from statistics import mean \n",
    "import os\n",
    "\n",
    "# predict result path\n",
    "input_file = 'formal_test/formal_chunk_size_32/predict_41348_test.txt'\n",
    "\n",
    "pos_file = input_file.replace(\".txt\",\"_pos.txt\")\n",
    "remove_duplicate_doctor_file = input_file.replace(\".txt\",\"_remove_duplicate_doctor.txt\")\n",
    "regex_file = input_file.replace(\".txt\",\"_regex.txt\")\n",
    "# regex_imp_file 為正規結果\n",
    "regex_imp_file = input_file.replace(\".txt\",\"_regex_entity_imp.txt\")\n",
    "\n",
    "data = pd.read_csv(input_file,keep_default_na=False, na_values=['NaN', 'null'], names=[\"file_id\", \"label\", \"start\", \"end\", \"entity\"], sep='\\t')\n",
    "# data = data.replace(\"\", pd.NA)\n",
    "# data = data.dropna()\n",
    "new_rows = []  # 用于存储新的行数据\n",
    "dp = r'(\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{2,4})|(\\d{2,4}[/.-]\\d{1,2}[/.-]\\d{1,2})|(\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{1,2})'\n",
    "tp = r'\\d+[:.]*\\d*[ ]*[pPaA]+[.]*[mM]+[.]*|\\d+[:.]*\\d*'\n",
    "tp_imp = r'\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{2,4}[ ][a][t][ ][\\d]+[:./][\\d]+[:./]?[\\d]*[pPaA]?[.]?[mM]?[.]?|[\\d]+[:./][\\d]+[:./]?[\\d]*[pPaA]?[.]?[mM]?[.]?[ ][o][n][ ]\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{2,4}'\n",
    "# tp_imp = r'\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{2,4}[ ][at][ ]\\d+[:./]\\d[:./]\\d[pPaA]?[.]?[mM]?[.]?|\\d+[:./]\\d[:./]\\d[pPaA]?[.]?[mM]?[.]?[ ][on][ ]\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{2,4}'\n",
    "# have_time = r'[Cc][Oo][Ll][Ll][Ee][Cc][Tt][Ee][Dd][ ]*[:]*[ (]*'\n",
    "\n",
    "# get time\n",
    "# answer = answer[answer['label']!=\"TIME\"]\n",
    "data = data.reset_index(drop=True)\n",
    "entity_group = data.groupby('file_id')\n",
    "all_file_name = os.listdir(\"/home/ting/code/AI_CUP_2023_Medical/TEST_DATASET/opendid_test\")\n",
    "for name in all_file_name:\n",
    "    with open(\"/home/ting/code/AI_CUP_2023_Medical/TEST_DATASET/opendid_test/\"+name) as f_w:\n",
    "        text = f_w.read()\n",
    "        # have_time_span = re.search(have_time,text)\n",
    "        # if have_time_span==None:\n",
    "        #     continue\n",
    "        # time_start = have_time_span.span()[1]\n",
    "        # time_span_text = \"\".join(list(text)[time_start:time_start+20])\n",
    "        time = re.search(tp_imp,text)\n",
    "        # print(time)\n",
    "        if time!=None:\n",
    "            entity = time.group()\n",
    "            start = time.span()[0]\n",
    "            end = time.span()[1]\n",
    "            error_entity = entity_group.get_group(name.split(\".\")[0]).query('start>=@start and end<=@end')\n",
    "            error_entity_index = error_entity.index.tolist()\n",
    "            # if error_entity_index==[]:\n",
    "            #     continue\n",
    "            # for i in entity_group.get_group(name.split(\".\")[0]).query('start>=@start and end<=@end').index.tolist():\n",
    "            data.drop(error_entity_index,inplace=True)\n",
    "            for char in ' .)':\n",
    "                left_noise_count = len(entity) - len(entity.lstrip(char))  # 计算前面的空格数量\n",
    "                right_noise_count = len(entity) - len(entity.rstrip(char))  # 计算后面的空格数量\n",
    "                start+=left_noise_count\n",
    "                end-=right_noise_count\n",
    "                entity = entity.strip(char)\n",
    "\n",
    "            time_entity = pd.DataFrame({\n",
    "                \"file_id\":name.split(\".\")[0],\n",
    "                \"label\":\"TIME\",\n",
    "                \"start\":start,\n",
    "                \"end\":end,\n",
    "                \"entity\":entity,\n",
    "                \"regular\":\"\"\n",
    "            }, index=[0])\n",
    "            data = data.append(time_entity)\n",
    "data = data.sort_values(by=['file_id',\"start\"])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    entity = row['entity']\n",
    "    start = row['start']\n",
    "    end = row['end']\n",
    "    for char in ' .-':\n",
    "        left_noise_count = len(entity) - len(entity.lstrip(char))  # 计算前面的空格数量\n",
    "        right_noise_count = len(entity) - len(entity.rstrip(char))  # 计算后面的空格数量\n",
    "        start+=left_noise_count\n",
    "        end-=right_noise_count\n",
    "        entity = entity.strip(char)\n",
    "    # 使用正则表达式将entity字符串分割成多个部分\n",
    "    if entity==\"\":\n",
    "        continue\n",
    "    if row['label']!='IDNUM' and len(row['entity'])<2:\n",
    "        continue\n",
    "    if is_country_name(entity):\n",
    "        if row['label']!=\"STREET\":\n",
    "            new_row = [row['file_id'], \"COUNTRY\", start, end, entity]\n",
    "            new_rows.append(new_row)\n",
    "            continue\n",
    "    if row['label']=='DURATION':\n",
    "        regx_date=[]\n",
    "        regx_date.extend(re.findall(r'[d]+[a]*[y]*[s]*',entity))\n",
    "        regx_date.extend(re.findall(r'[w]+[e]*[k]*[s]*',entity))\n",
    "        regx_date.extend(re.findall(r'[m]+[o]*[n]*[t]*[h]*[s]*',entity))\n",
    "        regx_date.extend(re.findall(r'[y]+[e]*[a]*[r]*[s]*',entity))\n",
    "        if regx_date==[]:\n",
    "            continue\n",
    "        else:\n",
    "            new_row = [row['file_id'], row['label'], start, end, entity]\n",
    "            new_rows.append(new_row)\n",
    "    elif row['label']=='TIME':\n",
    "        if len(entity)<5 and re.findall(r\"\\d\",entity):\n",
    "            continue\n",
    "        date_span = re.findall(dp,entity)\n",
    "        if date_span!=[]:\n",
    "            date_span = re.search(dp,entity)\n",
    "            lenght_date = date_span.span()[1]-date_span.span()[0]\n",
    "            if lenght_date==len(entity):\n",
    "                row['label'] = \"DATE\"\n",
    "        new_row = [row['file_id'], row['label'], start, end, entity]\n",
    "        new_rows.append(new_row)\n",
    "        \n",
    "    elif row['label']=='DATE':\n",
    "        if len(entity)<3:\n",
    "            continue\n",
    "        if \",\" in entity:\n",
    "            parts = re.split(r'[,]', entity)\n",
    "            for part in parts:\n",
    "                # part = part.strip()  # 去除前后的空格\n",
    "                left_empty_count = len(part) - len(part.lstrip())  # 计算前面的空格数量\n",
    "                right_empty_count = len(part) - len(part.rstrip())  # 计算后面的空格数量\n",
    "                noise_count = len(part) - len(part.rstrip('-'))\n",
    "                part_len = len(part)\n",
    "                part = part.strip()\n",
    "                part = part.strip('-')\n",
    "                if part:  # 如果部分不为空\n",
    "                    new_end = start + part_len\n",
    "                    new_row = [row['file_id'], row['label'], start+left_empty_count, new_end-right_empty_count-noise_count, part]\n",
    "                    new_rows.append(new_row)\n",
    "                    start = new_end+1  # 更新下一个部分的起始位置\n",
    "        else:\n",
    "            try:\n",
    "                date_span = re.search(dp, entity).span()\n",
    "                date = entity[date_span[0]:date_span[1]]\n",
    "                new_row = [row['file_id'], row['label'], start+date_span[0], start+date_span[0]+len(date), date]\n",
    "                new_rows.append(new_row)\n",
    "                \n",
    "            except:\n",
    "                new_row = [row['file_id'], row['label'], start, end, entity]\n",
    "                new_rows.append(new_row)\n",
    "    elif row['label']=='MEDICALRECORD' and \"(\" in entity:\n",
    "        parts = re.split(r'[(]', entity)\n",
    "        for part in parts:\n",
    "            # part = part.strip()  # 去除前后的空格\n",
    "            left_empty_count = len(part) - len(part.lstrip())  # 计算前面的空格数量\n",
    "            right_empty_count = len(part) - len(part.rstrip())  # 计算后面的空格数量\n",
    "            noise_count = len(part) - len(part.rstrip('-'))\n",
    "            part_len = len(part)\n",
    "            part = part.strip()\n",
    "            part = part.strip('-')\n",
    "            if part:  # 如果部分不为空\n",
    "                new_end = start + part_len\n",
    "                new_row = [row['file_id'], row['label'], start+left_empty_count, new_end-right_empty_count-noise_count, part]\n",
    "                new_rows.append(new_row)\n",
    "                start = new_end+1  # 更新下一个部分的起始位置\n",
    "\n",
    "    elif row['label']=='IDNUM':\n",
    "        parts = re.split(r'[,(]', entity)\n",
    "        for part in parts:\n",
    "            # part = part.strip()  # 去除前后的空格\n",
    "            left_empty_count = len(part) - len(part.lstrip())  # 计算前面的空格数量\n",
    "            right_empty_count = len(part) - len(part.rstrip())  # 计算后面的空格数量\n",
    "            noise_count = len(part) - len(part.rstrip('-'))\n",
    "            part_len = len(part)\n",
    "            part = part.strip()\n",
    "            part = part.strip('-')\n",
    "            if part:  # 如果部分不为空\n",
    "                new_end = start + part_len\n",
    "                new_row = [row['file_id'], row['label'], start+left_empty_count, new_end-right_empty_count-noise_count, part]\n",
    "                new_rows.append(new_row)\n",
    "                start = new_end+1  # 更新下一个部分的起始位置\n",
    "\n",
    "    elif row['label']=='DOCTOR':\n",
    "        if ';' in entity or '/' in entity:\n",
    "            parts = re.split(r'[;/]', entity)\n",
    "            for part in parts:\n",
    "                # part = part.strip()  # 去除前后的空格\n",
    "                left_empty_count = len(part) - len(part.lstrip())  # 计算前面的空格数量\n",
    "                right_empty_count = len(part) - len(part.rstrip())  # 计算后面的空格数量\n",
    "                if part:  # 如果部分不为空\n",
    "                    part_len = len(part)\n",
    "                    new_end = start + part_len\n",
    "                    new_row = [row['file_id'], row['label'], start+left_empty_count, new_end-right_empty_count, part.strip()]\n",
    "                    new_rows.append(new_row)\n",
    "                    start = new_end+1  # 更新下一个部分的起始位置\n",
    "        elif ':' in entity:\n",
    "            parts = re.split(r'[:]', entity)\n",
    "            left_empty_count = len(parts[1]) - len(parts[1].lstrip())  # 计算前面的空格数量\n",
    "            right_empty_count = len(parts[1]) - len(parts[1].rstrip())  # 计算后面的空格数量\n",
    "            if parts[1]:  # 如果部分不为空\n",
    "                # part_len = len(part)\n",
    "                new_end = end\n",
    "                new_row = [row['file_id'], row['label'], start+len(parts[0])+left_empty_count+1, new_end-right_empty_count, parts[1].strip()]\n",
    "                new_rows.append(new_row)\n",
    "                # start = new_end+1  # 更新下一个部分的起始位置\n",
    "        elif '(' in entity:\n",
    "            parts = re.split(r'[(]', entity)\n",
    "            left_empty_count = len(parts[0]) - len(parts[0].lstrip())  # 计算前面的空格数量\n",
    "            right_empty_count = len(parts[0]) - len(parts[0].rstrip())  # 计算后面的空格数量\n",
    "            if parts[1]:  # 如果部分不为空\n",
    "                # part_len = len(part)\n",
    "                new_end = end\n",
    "                new_row = [row['file_id'], row['label'], start+left_empty_count, new_end-len(parts[1])-right_empty_count-1, parts[0].strip()]\n",
    "                new_rows.append(new_row)\n",
    "                # start = new_end+1  # 更新下一个部分的起始位置\n",
    "        else:\n",
    "            new_row = [row['file_id'], row['label'], start, end, entity]\n",
    "            new_rows.append(new_row)\n",
    "    else:\n",
    "        new_row = [row['file_id'], row['label'], start, end, entity]\n",
    "        new_rows.append(new_row)\n",
    "\n",
    "# 创建一个新的数据帧，包含拆分后的行数据\n",
    "new_data = pd.DataFrame(new_rows, columns=['file_id', 'label', 'start', 'end', 'entity'])\n",
    "\n",
    "# 打印处理后的数据\n",
    "# print(new_data)\n",
    "new_data.to_csv(pos_file, sep='\\t', index=False,header=None)\n",
    "\n",
    "#remove_duplicate_doctor(2)\n",
    "data = new_data\n",
    "# data = pd.read_csv('p_eval_answer/formal_roberta-large_allsplit_F1_?/predict_29532_epoch6_predict_pos.txt',keep_default_na=False, names=[\"file_id\", \"label\", \"start\", \"end\", \"entity\",\"regular_time\"], sep='\\t')\n",
    "entity_group = data.groupby('file_id')\n",
    "file_name = entity_group.groups.keys()\n",
    "remove_duplicate_doctor=pd.DataFrame()\n",
    "for i,name in enumerate(file_name):\n",
    "    group = entity_group.get_group(name)\n",
    "    # df_unique = group.drop_duplicates(keep=False)\n",
    "    df_doctors = group[group['label'] == 'DOCTOR']\n",
    "    df_another = group[group['label'] != 'DOCTOR']  \n",
    "    df_unique_doctors = df_doctors.drop_duplicates(subset=['entity'], keep=False)\n",
    "    df_cleaned = pd.concat([df_another, df_unique_doctors])\n",
    "    df_cleaned = df_cleaned.sort_values(['start'])\n",
    "    remove_duplicate_doctor = pd.concat([remove_duplicate_doctor, df_cleaned])\n",
    "    # print(df_cleaned)\n",
    "    # break\n",
    "\n",
    "remove_duplicate_doctor.to_csv(remove_duplicate_doctor_file, sep='\\t', index=False,header=None)\n",
    "#regex(3)\n",
    "answer = pd.read_csv(remove_duplicate_doctor_file,keep_default_na=False, na_values=['NaN', 'null'],names=[\"file_id\",\"label\",\"start\",\"end\",\"entity\",\"regular\"], delimiter='\\t',)\n",
    "\n",
    "# if len(text)<10:\n",
    "#     text = text.replace(\" \", \"\")\n",
    "# 12:00 \n",
    "dp = r'(\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{2,4})|(\\d{2,4}[/.-]\\d{1,2}[/.-]\\d{1,2})|(\\d{1,2}[/.-]\\d{1,2}[/.-]\\d{1,2})'\n",
    "mp = r'([\\d:]+)(\\w+)'\n",
    "p_m = r\"(\\d+[:.]*\\d*[:.]*\\d*)([pPaA]+[.]*[mM]+[.]*)?\"\n",
    "dp_again = r'(\\d{4})(\\d{2})(\\d{2})|(\\d{4})(\\d{2})(\\d{1})'\n",
    "previous_year = \"\"\n",
    "previous_regular = \"\"\n",
    "fix_date_M_D_Y = open(\"/home/ting/code/ehr_deidentification/fix_date(M_D_Y).txt\").read().split(\"\\n\")\n",
    "\n",
    "with open(\"weird_ALL_TEST.txt\",\"w\") as w_f:\n",
    "    for ans_idx, ans_item in answer.iterrows():\n",
    "        # print(item['label'])\n",
    "        try:\n",
    "            if ans_item['label'] == 'TIME': \n",
    "                date=\"\"\n",
    "                text = ans_item['entity']\n",
    "\n",
    "                text = text.strip()\n",
    "                if 'at' in text and 'on' in text :\n",
    "                    text = text.split()[1:]\n",
    "                    text = \" \".join(text)\n",
    "                if 'at' in text or '@' in text:\n",
    "                    if 'at' in text:\n",
    "                        parts = text.split('at')\n",
    "                        time = parts[1].strip().replace(\" \",\"\")\n",
    "                        date = parts[0]\n",
    "                    if  '@' in text:\n",
    "                        parts = text.split('@')\n",
    "                        time = parts[1].strip().replace(\" \",\"\")\n",
    "                        date = parts[0]\n",
    "                    if re.findall(dp, text)!=[]:\n",
    "                        date_span = re.search(dp, text).span()\n",
    "                        date = text[date_span[0]:date_span[1]]\n",
    "                        if date_span[0]>0:\n",
    "                            text_time = text[:date_span[0]].strip()\n",
    "                        else:\n",
    "                            text_time = text[date_span[1]:].strip()\n",
    "                        time = text_time\n",
    "                else:\n",
    "                    if 'on' in text:\n",
    "                        parts = text.split('on')\n",
    "                        time = parts[0].strip().replace(\" \",\"\")\n",
    "                        date = parts[1]\n",
    "                    elif \"of\" in text:\n",
    "                        parts = text.split()\n",
    "                        time = parts[0].strip().replace(\" \",\"\")\n",
    "                        date = \" \".join(parts[1:])\n",
    "                    else:\n",
    "                        parts = text.split()\n",
    "                    # print(re.findall(dp, text))\n",
    "                    if re.findall(dp, text)!=[]:\n",
    "                        date_span = re.search(dp, text).span()\n",
    "                        date = text[date_span[0]:date_span[1]]\n",
    "                        if date_span[0]>0:\n",
    "                            text_time = text[:date_span[0]].strip()\n",
    "                        else:\n",
    "                            text_time = text[date_span[1]:].strip()\n",
    "                    else:\n",
    "                        text_time = text.replace(\" \",\"\")\n",
    "                    time = text_time\n",
    "\n",
    "                time = time.replace(\" \",\"\")\n",
    "                time =list(re.findall(p_m, time)[0])\n",
    "                # print(time)\n",
    "\n",
    "                time[0] = time[0].replace(\".\",\":\")\n",
    "                if len(time[0])==4 and \":\" not in time[0]:\n",
    "                    time_hour_second = list(re.findall(r'(\\d{1,2})([:.])*(\\d{1,2})', time[0])[0])\n",
    "                else:\n",
    "\n",
    "                    try:\n",
    "                        time_hour_second = list(re.findall(r'(\\d{1,2})([:.])+(\\d*)([:.])*(\\d*)', time[0])[0])\n",
    "                    except:\n",
    "                        time_hour_second = list(re.findall(r'(\\d{1,2})([:.])*(\\d*)([:.])*(\\d*)', time[0])[0])\n",
    "                if len(time_hour_second)>3 and time_hour_second[3]==\"\" and time_hour_second[4]==\"\":\n",
    "                    time_hour_second = time_hour_second[:3]\n",
    "                time_hour_second[1]=\":\"\n",
    "                if time_hour_second[2]==\"\":\n",
    "                    time_hour_second[2]=\"00\"\n",
    "                if len(time_hour_second[2])>2:\n",
    "                    time_hour_second[2] = time_hour_second[2][:2]\n",
    "                tail = time_hour_second[-1]\n",
    "                time_hour_second_sub = time_hour_second[:3]\n",
    "\n",
    "                if time[1]==\"\":\n",
    "                    time = ''.join(time_hour_second_sub)\n",
    "                    try:\n",
    "                        time =  datetime.strptime(time, '%I:%M%p').strftime('%H:%M')\n",
    "                    except:\n",
    "                        time =  datetime.strptime(time, '%H:%M').strftime('%H:%M')\n",
    "                elif time[1]!=[]:\n",
    "                    \n",
    "                    time_regular = ''.join(time_hour_second_sub)+time[1].replace(\".\",\"\")\n",
    "                    try:\n",
    "                        time =  datetime.strptime(time_regular, '%I:%M%p').strftime('%H:%M')\n",
    "                    except:\n",
    "                        time_regular = ''.join(time_hour_second_sub)\n",
    "                        time =  datetime.strptime(time_regular, '%H:%M').strftime('%H:%M')\n",
    "                if time == \"00:00\":\n",
    "                    time = \"00:00:00\"\n",
    "                elif len(time_hour_second)>3:\n",
    "                    time = time+\":\"+tail\n",
    "                if 'of' in text and time!=[]:\n",
    "\n",
    "                    tmp_date = date.split('of')\n",
    "                    date_day = tmp_date[0]\n",
    "                    day = re.findall(mp, date_day)[0][0]\n",
    "                    date_month_year = tmp_date[1]\n",
    "                    date_month_year_list = date_month_year.split()\n",
    "                    year = date_month_year_list[-1]\n",
    "                    for item in date_month_year_list[:-1]:\n",
    "                        try:\n",
    "                            date_object = datetime.strptime(item, '%B')\n",
    "                            month = str(date_object.month)\n",
    "                        except:\n",
    "                            month_matches = re.findall(mp, item)\n",
    "                            if month_matches!=[]:\n",
    "                                month = str(month_matches[0][0])\n",
    "                    if len(day)==1:\n",
    "                        day=\"0\"+day\n",
    "                    if len(month)==1:\n",
    "                        month=\"0\"+month\n",
    "                    regular_all = year+\"-\"+month+\"-\"+day+\"T\"+time\n",
    "                else:\n",
    "                    try:\n",
    "                        if date!=[]:\n",
    "                            date = date.replace(\" \",\"\")\n",
    "                            date = date.replace(\".\",\"/\")\n",
    "                            date = date.replace(\"-\",\"/\")\n",
    "                            date_matches = re.search(dp, date)\n",
    "                            if date_matches:\n",
    "                                date = date_matches.group()\n",
    "                            date_split = date.split('/')\n",
    "                            for idx, item in enumerate(date_split):\n",
    "                                if(len(item)==1):\n",
    "                                    date_split[idx] = '0' + item\n",
    "                            if len(date_split[0])==2 and len(date_split[1])==2 and len(date_split[2])==4:\n",
    "                                year = date_split[2]\n",
    "                                month = date_split[1]\n",
    "                                day = date_split[0]\n",
    "                            elif len(date_split[0])==4 and len(date_split[1])==2 and len(date_split[2])==2:\n",
    "                                year = date_split[0]\n",
    "                                month = date_split[1]\n",
    "                                day = date_split[2]\n",
    "                            elif len(date_split[0])==2 and len(date_split[1])==2 and len(date_split[2])==2:\n",
    "                                year = '20'+ date_split[2]\n",
    "                                month = date_split[1]\n",
    "                                day = date_split[0]\n",
    "                            regular_all = year+\"-\"+month+\"-\"+day+\"T\"+time\n",
    "                        else:\n",
    "                            regular_all = time\n",
    "                    except:\n",
    "                        regular_all = time\n",
    "                # assert answer['regular'][i]==regular_all\n",
    "                answer['regular'][ans_idx]=regular_all\n",
    "\n",
    "            \n",
    "                # print(answer['regular'][i],i)\n",
    "            elif ans_item['label'] == 'SET':\n",
    "                answer['regular'][ans_idx] = reg_set_new(ans_item['entity'])\n",
    "            elif ans_item['label'] == 'DURATION':\n",
    "                text = ans_item['entity']\n",
    "                try:\n",
    "                    regx_number =  re.findall(r'[\\d]+',text)  \n",
    "                    regx_number = [int(x) for x in regx_number]\n",
    "                    number = mean(regx_number)\n",
    "                except:\n",
    "                    regx_number = []\n",
    "                # print(text,regx_number)\n",
    "                regx_date = []\n",
    "                regx_date.extend(re.findall(r'([d]+[a]*[y]*[s]*)',text))\n",
    "                regx_date.extend(re.findall(r'([w]+[e]*[k]*[s]*)',text))\n",
    "                regx_date.extend(re.findall(r'([m]+[o]*[n]*[t]*[h]*[s]*)',text))\n",
    "                regx_date.extend(re.findall(r'([y]+[e]*[a]*[r]*[s]*)',text))\n",
    "                # print(number,regx_date)\n",
    "\n",
    "                # print(regx_date)\n",
    "                if regx_date!=[] and regx_number!=[]:\n",
    "                    regx_date = regx_date[0]\n",
    "                    # print(number,regx_date)\n",
    "                    # number = regx_date[0]\n",
    "                    # print(\"P\"+number+regx_date[1][0].upper())\n",
    "                    answer['regular'][ans_idx] = \"P\"+str(number)+regx_date[0].upper()\n",
    "                    # print(answer['regular'][ans_idx])\n",
    "\n",
    "                if regx_number==[]:\n",
    "                    # print(text)\n",
    "                    regx_date=[]\n",
    "                    text = text.split()\n",
    "                    number = \" \".join(text[:-1]).replace(\"-\",\" \").replace(\".\",\" \")\n",
    "                    # print(number,text)\n",
    "                    regx_date.extend(re.findall(r'([d]+[a]*[y]*[s]*)',text[-1]))\n",
    "                    regx_date.extend(re.findall(r'([w]+[e]*[k]*[s]*)',text[-1]))\n",
    "                    regx_date.extend(re.findall(r'([m]+[o]*[n]*[t]*[h]*[s]*)',text[-1]))\n",
    "                    regx_date.extend(re.findall(r'([y]+[e]*[a]*[r]*[s]*)',text[-1]))\n",
    "                    # print(\"P\"+str(text2int(number))+regx_date[0][0].upper())\n",
    "                    try:\n",
    "                        if text2int(number)==0:\n",
    "                            # print(text)\n",
    "                            # answer['regular'][ans_idx] = \"P\"+str(text2int(number)+1)+regx_date[0][0].upper()\n",
    "                            answer = answer.drop(ans_idx)\n",
    "                            # continue\n",
    "                        else:\n",
    "                            answer['regular'][ans_idx] = \"P\"+str(text2int(number))+regx_date[0][0].upper()\n",
    "                    except:\n",
    "                        answer = answer.drop(ans_idx)\n",
    "            elif ans_item['label'] == 'DATE':\n",
    "                if ans_item['entity'] in fix_date_M_D_Y:\n",
    "                    flag=1\n",
    "                else:\n",
    "                    flag=0\n",
    "                find_month = Find_Month(ans_item['entity'])\n",
    "                # if ans_item['file_id'] == \"840\":\n",
    "                #     print(ans_item['entity'],find_month)\n",
    "                if find_month!=[] and 'of' not in ans_item['entity']:\n",
    "                    month_span = re.search(find_month[0],ans_item['entity']).span()\n",
    "                    month = ans_item['entity'][month_span[0]:month_span[1]]\n",
    "                    month = Month_format(month)\n",
    "                    date_object = datetime.strptime(month, '%B')\n",
    "                    month = str(date_object.month)\n",
    "                    if len(month)==1:\n",
    "                        month = \"0\"+month\n",
    "                    if month_span[0]==0:\n",
    "                        year = ans_item['entity'][month_span[1]:].strip()\n",
    "                    else:\n",
    "                        year = ans_item['entity'][:month_span[0]].strip()\n",
    "                    # print(month_span[0])\n",
    "                    regular_all = year+\"-\"+month\n",
    "                elif 'of' in ans_item['entity']:\n",
    "                    date_list = []\n",
    "                    tmp_date = ans_item['entity'].split('of')\n",
    "                    date_day = tmp_date[0]\n",
    "                    day = re.findall(mp, date_day)[0][0]\n",
    "                    date_month_year = tmp_date[1]\n",
    "                    date_list.append(day)\n",
    "                    date_month_year_list = date_month_year.split()\n",
    "                    if len(date_month_year_list)==1:\n",
    "                        # re.sub(r'a', 'b', 'banana')\n",
    "                        try:\n",
    "                            date_object = datetime.strptime(date_month_year_list[0], '%B')\n",
    "                            month = str(date_object.month)\n",
    "                        except:\n",
    "                            month_matches = re.findall(mp, date_month_year_list[0])\n",
    "                            if month_matches!=[]:\n",
    "                                month = str(month_matches[0][0])\n",
    "                            else:\n",
    "                                month = Month_format(date_month_year_list[0])\n",
    "                                date_object = datetime.strptime(month, '%B')\n",
    "                                month = str(date_object.month)\n",
    "                        date_list.insert(0,month)\n",
    "                        if len(day)==1:\n",
    "                            day=\"0\"+day\n",
    "                        if len(month)==1:\n",
    "                            month=\"0\"+month\n",
    "                        date_list.insert(0,previous_year)\n",
    "                        regular_all = \"-\".join(date_list)\n",
    "                    else:\n",
    "                        year = date_month_year_list[-1]\n",
    "                        for item in date_month_year_list[:-1]:\n",
    "                            try:\n",
    "                                date_object = datetime.strptime(item, '%B')\n",
    "                                month = str(date_object.month)\n",
    "                            except:\n",
    "                                month_matches = re.findall(mp, item)\n",
    "                                if month_matches!=[]:\n",
    "                                    month = str(month_matches[0][0])\n",
    "                                else:\n",
    "                                    month = Month_format(date_month_year_list[0])\n",
    "                                    date_object = datetime.strptime(month, '%B')\n",
    "                                    month = str(date_object.month)\n",
    "                        if len(day)==1:\n",
    "                            day=\"0\"+day\n",
    "                        if len(month)==1:\n",
    "                            month=\"0\"+month\n",
    "                        previous_year = year\n",
    "                        regular_all = year+\"-\"+month+\"-\"+day\n",
    "                else:\n",
    "                    date = ans_item['entity'].replace(\" \",\"/\").replace(\",\",\"/\")\n",
    "                    date = date.replace(\".\",\"/\")\n",
    "                    date = date.replace(\"-\",\"/\")\n",
    "                    date_matches = re.search(dp, date)\n",
    "                    if date_matches:\n",
    "                        date = date_matches.group()\n",
    "                    # print(date)\n",
    "                    date_split = date.split('/')\n",
    "                    date_split = list(filter(None, date_split))\n",
    "                    if len(date_split)==1:\n",
    "                        date_split_again = re.findall(dp_again,date)\n",
    "                        # print(date_split_again)\n",
    "                        if date_split_again!=[]:\n",
    "                            date_split_again = list(date_split_again[0])\n",
    "                            date_split_again = list(filter(None, date_split_again))\n",
    "                            # if ans_item['file_id'] == \"file5124\":\n",
    "                            #     print(date_split_again)\n",
    "                            if len(date_split_again[-1])==1:\n",
    "                                date_split_again[-1] = date_split_again[-1]+\"0\"\n",
    "                                answer['end'][ans_idx] = str(int(answer['end'][ans_idx])+1)\n",
    "                                answer['entity'][ans_idx] = answer['entity'][ans_idx]+\"0\"\n",
    "                            regular_all = \"-\".join(date_split_again)\n",
    "                        else:\n",
    "                            try:\n",
    "                                error = int(date_split[0])\n",
    "                                regular_all = date_split[0]\n",
    "                            except:\n",
    "                                # if re.findall(r\"[Tt][Oo][Dd][Aa][Yy]\",ans_item['entity'])!=[]:\n",
    "                                #     regular_all = \"2062-09-13\"\n",
    "                                # elif re.findall(r\"[Pp][Rr][Ee][Vv][Ii][Oo][Uu][Ss]\",ans_item['entity'])!=[]:\n",
    "                                #     regular_all = \"2064-05-27\"\n",
    "                                # elif re.findall(r\"[Nn][Oo][Ww]\",ans_item['entity'])!=[]:\n",
    "                                #     regular_all = \"2062-11-27\"\n",
    "                                # regular_all = previous_regular\n",
    "                                print(date_split)\n",
    "                                continue\n",
    "                    elif len(date_split)==2:\n",
    "                        for i,item in enumerate(date_split):\n",
    "                            if len(item)<2:\n",
    "                                date_split[i] = \"0\"+date_split[i]\n",
    "                        if len(date_split[0])==2 and len(date_split[-1])==2:\n",
    "                            year = '20'+ date_split[-1]\n",
    "                            month = date_split[0]\n",
    "                        elif len(date_split[0])==2 and len(date_split[-1])==4:\n",
    "                            year = date_split[-1]\n",
    "                            month = date_split[0]\n",
    "                        elif len(date_split[0])==4 and len(date_split[-1])==2:\n",
    "                            year = date_split[0]\n",
    "                            month = date_split[-1]\n",
    "                        regular_all = year+\"-\"+month\n",
    "\n",
    "                    else:\n",
    "                        for idx, item in enumerate(date_split):\n",
    "                            if len(item)<2:\n",
    "                                date_split[idx] = '0' + item\n",
    "\n",
    "                        if len(date_split[0])==2 and len(date_split[1])==2 and len(date_split[2])==4:\n",
    "                            year = date_split[2]\n",
    "                            if flag or int(date_split[1])>12:\n",
    "                                month = date_split[0]\n",
    "                                day = date_split[1]\n",
    "                            else:\n",
    "                                day = date_split[0]\n",
    "                                month = date_split[1]\n",
    "                            \n",
    "                        elif len(date_split[0])==4 and len(date_split[1])==2 and len(date_split[2])==2:\n",
    "                            year = date_split[0]\n",
    "                            month = date_split[1]\n",
    "                            day = date_split[2]\n",
    "                        elif len(date_split[0])==2 and len(date_split[1])==2 and len(date_split[2])==2:\n",
    "                            year = '20'+ date_split[2]\n",
    "                            if flag or int(date_split[1])>12:\n",
    "                                month = date_split[0]\n",
    "                                day = date_split[1]\n",
    "                            else:\n",
    "                                day = date_split[0]\n",
    "                                month = date_split[1]\n",
    "\n",
    "                        regular_all = year+\"-\"+month+\"-\"+day\n",
    "                previous_year = year\n",
    "                previous_regular = regular_all\n",
    "                answer['regular'][ans_idx] = regular_all\n",
    "            else:\n",
    "                regular_all = \"\"\n",
    "        except:\n",
    "            w_f.write(\"\\t\".join(list(map(str,answer.iloc[i].tolist())))+\"\\n\")\n",
    "\n",
    "    # print(item)\n",
    "answer.to_csv(regex_file, sep='\\t', index=False,header=None)\n",
    "\n",
    "with open(regex_file,\"r\") as reg_r:\n",
    "    reg_list = reg_r.readlines()\n",
    "with open(regex_file,\"w\") as reg_w:\n",
    "    # print(x)\n",
    "    for line in reg_list:\n",
    "        # print()\n",
    "        reg_w.write(line.rstrip(\"\\t\\n\")+\"\\n\")\n",
    "\n",
    "answer = pd.read_csv(regex_file,keep_default_na=False, na_values=['NaN', 'null'],names=[\"file_id\",\"label\",\"start\",\"end\",\"entity\",\"regular\"], delimiter='\\t',)\n",
    "answer = answer[answer['label']!=\"LOCATION-OTHER\"]\n",
    "answer = answer.reset_index(drop=True)\n",
    "entity_group = answer.groupby('file_id')\n",
    "all_file_name = os.listdir(\"/home/ting/code/AI_CUP_2023_Medical/TEST_DATASET/opendid_test\")\n",
    "for name in all_file_name:\n",
    "    with open(\"/home/ting/code/AI_CUP_2023_Medical/TEST_DATASET/opendid_test/\"+name) as f_w:\n",
    "        text = f_w.read()\n",
    "        location_other = re.search(r'[Pp][.]?[Oo][.]?[ ][Bb][Oo][Xx][ ][\\d]{0,5}',text)\n",
    "        if location_other!=None:\n",
    "            entity = location_other.group()\n",
    "            start = location_other.span()[0]\n",
    "            end = location_other.span()[1]\n",
    "            for i in entity_group.get_group(name.split(\".\")[0]).query('start>=@start and end<=@end').index.tolist():\n",
    "                answer.drop(i,inplace=True)\n",
    "            location_other_entity = pd.DataFrame({\n",
    "                \"file_id\":name.split(\".\")[0],\n",
    "                \"label\":\"LOCATION-OTHER\",\n",
    "                \"start\":start,\n",
    "                \"end\":end,\n",
    "                \"entity\":entity,\n",
    "                \"regular\":\"\"\n",
    "            }, index=[0])\n",
    "            answer = answer.append(location_other_entity, ignore_index=True)\n",
    "answer = answer.sort_values(by=['file_id',\"start\"])\n",
    "answer = answer.reset_index(drop=True)\n",
    "\n",
    "# get url\n",
    "answer = answer[answer['label']!=\"URL\"]\n",
    "answer = answer.reset_index(drop=True)\n",
    "entity_group = answer.groupby('file_id')\n",
    "all_file_name = os.listdir(\"/home/ting/code/AI_CUP_2023_Medical/TEST_DATASET/opendid_test\")\n",
    "for name in all_file_name:\n",
    "    with open(\"/home/ting/code/AI_CUP_2023_Medical/TEST_DATASET/opendid_test/\"+name) as f_w:\n",
    "        text = f_w.read()\n",
    "        url = re.search(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\'(),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+',text)\n",
    "        if url!=None:\n",
    "            entity = url.group()\n",
    "            start = url.span()[0]\n",
    "            end = url.span()[1]\n",
    "            for i in entity_group.get_group(name.split(\".\")[0]).query('start>=@start and end<=@end').index.tolist():\n",
    "                answer.drop(i,inplace=True)\n",
    "            for char in ' .)':\n",
    "                left_noise_count = len(entity) - len(entity.lstrip(char))  # 计算前面的空格数量\n",
    "                right_noise_count = len(entity) - len(entity.rstrip(char))  # 计算后面的空格数量\n",
    "                start+=left_noise_count\n",
    "                end-=right_noise_count\n",
    "                entity = entity.strip(char)\n",
    "\n",
    "            url_entity = pd.DataFrame({\n",
    "                \"file_id\":name.split(\".\")[0],\n",
    "                \"label\":\"URL\",\n",
    "                \"start\":start,\n",
    "                \"end\":end,\n",
    "                \"entity\":entity,\n",
    "                \"regular\":\"\"\n",
    "            }, index=[0])\n",
    "            answer = answer.append(url_entity, ignore_index=True)\n",
    "answer = answer.sort_values(by=['file_id',\"start\"])\n",
    "answer = answer.reset_index(drop=True)\n",
    "\n",
    "answer.to_csv(regex_imp_file, sep='\\t', index=False,header=None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ehr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
